# anr-rnn
This is based on mtg-rnn by billzorn, a fork of char-rnn by karpathy.

https://github.com/billzorn/mtg-rnn

That project has documentation for most of the code's features. This readme will focus mainly on my modifications and getting the code up and running.

Most of the original code is untouched. The biggest changes I've made to the lua scripts are updating sample_hs_v3.lua to have it recognize Netrunner field names instead of Magic ones (the script has been renamed to anr_sample.lua), and removing the "randomize mana" and "randomize fields" options from the training script.

I've also added an encoder which can process netrunner card data so that it is readable by the training script, and a decoder which can process the rnn's output and save it as a file that can be opened in Magic Set Editor using my Netrunner templates. Sampling can now be handled by the sample.py script which runs the sampler and then hands it off to the decoder automatically.

## NEW STUFF

Just documentation for stuff I've added and changed. If you want to get up and running, check out the HOW TO USE section below first.

### anrencode
anr_encode.py takes a json file downloaded from the netrunnerdb API  (/api/2.0/public/cards) and converts it to a format suitable for training in the RNN (similar to the ones created by billzorn's mtgencode).

Essentially it does the following:
 - Makes text lowercase
 - Replaces numbers 0-10 with unary (4 becomes &^^^^, 0 becomes &)
 - Replaces clicks - {O}, credits - {C}, traces - {#}, link - {L}, mu - {M}, recurrent credits - {R}, subroutine - >
 - Removes excess formatting (bold text, errata, etc.)
 - Removes "Interface", "Interrupt", "Access" keywords (We're going old-school).
 - Outputs two files (one including runner cards, and the other including corp cards) formatted as follows:
 
 Corp Cards:
|1type|2keywords|3faction|4influence|5strength|6uniqueness|7advancement cost|8agenda points|9influence limit|10minimum deck size|11text|12cost|13title|14trash cost|

 Runner Cards:
|1type|2keywords|3faction|4influence|5strength|6uniqueness|7base link|8memory cost|9influence limit|10minimum deck size|11text|12cost|13title|

When run from the command line, it will take the following arguments:
--input (takes a json file in the same directory as the script. Will default to cards.json if no argument is provided)
--output (will append this string to the end of each output file ex. runneroutput.txt, corpoutput.txt. Default is "_processed")

### anrdecode
anrdecode takes a text file generated by anr-rnn and converts it to a format that is readable by Magic Set Editor. It will output an mse-set file which can then be opened by MSE using my androidnetrunner templates.

### sample.py
sample.py is a python script used to link together the sampling script with anr_decode.

A sample command is:
```python3 sample.py --side runner --checkpoint cv/runner/YOURCHECKPOINT
```
Replace "cv/runner/YOURCHECKPOINT" with the location of the checkpoint you want to use.
This will run the sampling script and then the decoder, outputting a file in the anrdecode directory which you can then load into MSE.

Parameters:
--side is reccommended or else you may get incorrect output. This can be set to "runner" or "corp" and it should match the type of training data your checkpoint is based on. If a side is not provided, the script will attempt to figure it out on it's own but I can't guarantee that it will always be correct.
--script will select the sampler you would like to use. By default it will use "anr_sample.lua" which includes optional text priming features, but you can instead specify "sample.lua" to use the original script instead.
--length lets you change the number of characters that will be generated (default is 20000 which translates to approximately 100 cards).
--temperature allows you to adjust how much risk the rnn will take. Higher values lead to more unpredictable results (default is 0.8).
--gpuid, if set to 0, will use gpu instead of cpu. Only sample via gpu with checkpoints which were produced using gpu and vice versa (default is -1 for cpu).
--verbose, if set to 1, will print diagnostics before printing the sampled cards (default is 0). anrdecode will discard this anyway so it's not very useful unless you're running sample.lua on it's own.

If you are using the anr_sample.lua or default script, you can optionally include any of the following parameters to prime that field for each of the generated cards:
--cardtype
--keywords
--faction
--influence
--strength
--uniqueness
--advancementcost_baselink
--agendapoints_memorycost
--influencelimit
--decksize
--text
--cost
--title
--trashcost
(Note that advancementcost and baselink share a field as do agenda points and memory cost. Just put in the appropriate value depending on if you are sampling runner or corp cards.)
(Also note that python requires -- for arguments when running from the command line whereas lua requires just -)

###anr_sample.lua

This is a modification of "sample_hs_v3.lua" by Talcos from mtg-rnn. It has been edited to allow text priming on netrunner fields instead of magic fields. This script is run automatically by sample.py so you don't have to use it unless you want to run the script separately. You can run `th sample.lua -help` for more information.

# HOW TO USE

## Installation
Run this on Linux. Put the anr-rnn folder in your Home folder or wherever (this guide will assume you have put it in your Home folder).

Install dependancies:

Torch:

```bash
$ curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash
$ git clone https://github.com/torch/distro.git ~/torch --recursive
$ cd ~/torch; 
$ ./install.sh      # and enter "yes" at the end to modify your bashrc
$ source ~/.bashrc
```

Luarocks packages:

```bash
$ luarocks install nngraph 
$ luarocks install optim
$ luarocks install nn
```

You will also need to make sure you have Python 3 and pip installed.

Check if installed:

```bash
$ python3 --version
```

If not installed:

```bash
$ sudo apt-get update
$ sudo apt-get install python3
```

Install nltk and regex via pip:
```bash
pip install nltk
pip install regex
```

Install nltk punkt module:
```bash
python3
import nltk
nltk.download('punkt')
quit()
```
## Training
Now you can run the code!
Navigate to the anr-rnn installation. The rest of the commands must be run from this location so make sure to get back here if you close the terminal.
```bash
cd anr-rnn
```

If you want to train the model on your data, run the following command:
```bash
th train.lua -data_dir data/netrunner-runner -checkpoint_dir cv/runner
```
Make sure to replace "data/netrunner-runner" with the directory containing your training data file, and make sure that the data file is named "input.txt".
Note that we train on runner cards and corp cards separately to prevent the bot from getting too confused.
Also make sure to replace "cv/runner" with the directory where you want your files to be output.

Parameters: 
Use ` th train.lua -help` for a complete list of optional parameters. There are a lot of possibilities that you can tweak which will produce different results. For a more detailed overview of what some of these do, please see karpathy's original documentation for char-rnn:
https://github.com/karpathy/char-rnn

If you are using the default input, we have a very small dataset which means that the results probably aren't going to be that great. The best training commands I've come up with so far are:
```th train.lua -data_dir data/netrunner-corp -batch_size 20 -seq_length 20 -max_epochs 22 -checkpoint_dir cv/Corp1.0
```
And then:
```th train.lua -data_dir data/netrunner-corp -batch_size 20 -seq_length 20 -max_epochs 20 -dropout 0.8 -init_from cv/Corp1.0/YOURCHECKPOINTNAME -checkpoint_dir cv/Corp1.1
```
Replacing YOURCHECKPOINTNAME with the final checkpoint generated from the first command.

I encourage you to experiment though!

## Sampling
Once the model is finished training, you can generate cards using the following command:

```python3 sample.py --side corp --checkpoint cv/Corp/YOURCHECKPOINT.t7
```
Replace "cv/Corp/YOURCHECKPOINT.t7" with the location of the checkpoint you want to use. Also replace "corp" with "runner if you trained on runner cards.

Full documentation for this script can be found earlier in the README, in the sample.py section.

# CREDITS:

Card Designs by u/mnemic2: https://www.reddit.com/r/Netrunner/comments/fh754l/mnemics_custom_card_generator_for_android/
(There are small differences in how the cards look due to the shift to MSE)

Card Back icons by u/SpencerDub: https://www.reddit.com/r/Netrunner/comments/beu869/announcing_system_backup_proxy_backs/

Thanks to u/treiral for a previous attempt at creating Netrunner MSE templates and for the foundation of the symbol-font script: https://www.reddit.com/r/Netrunner/comments/1srgzt/runners_templates_for_mse/

anr-rnn based on mtg-rnn by billzorn which was in turn based on char-rnn by karpathy.
https://github.com/billzorn/mtg-rnn
https://github.com/karpathy/char-rnn

anr_sample.lua is a modification of the "sample_hs_v3.lua" script by Talcos found in Billzorn's fork

anrencode inspired by mtgencode by billzorn (specifically the style of the resulting files): https://github.com/billzorn/mtgencode

## License
MIT
